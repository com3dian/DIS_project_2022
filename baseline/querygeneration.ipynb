{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "querygeneration.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!java -version\n",
        "!pip install findspark"
      ],
      "metadata": {
        "id": "XxHPufpd9j3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import desc\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "## You can add more config while building \n",
        "spark = SparkSession.builder.master(\"local[8]\").\\\n",
        "                    config(\"spark.app.name\",\"session_one\").\\\n",
        "                    getOrCreate() #number of threads = 16"
      ],
      "metadata": {
        "id": "viyNlUU92Ksw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"testpeople.csv\",header=True,inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "id": "zPSvflmE7nwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def listOfFrequencyTables(df): #take main dataframe, generate frequency dataframes\n",
        "  histograms = []\n",
        "  for col in df.dtypes:\n",
        "      h=df.groupBy(col[0]).count()\n",
        "      h = h.sort(desc(\"count\"))\n",
        "      histograms.append(h)\n",
        "      h.show() #comment this line to suppress output\n",
        "  return histograms\n",
        "histograms = listOfFrequencyTables(df)"
      ],
      "metadata": {
        "id": "6vqZ5TqK7q2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a984cd-0ef2-4dea-82ea-7ca696928abc"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Name|count|\n",
            "+----+-----+\n",
            "|Nick|    4|\n",
            "|Mary|    3|\n",
            "|John|    3|\n",
            "+----+-----+\n",
            "\n",
            "+---------+-----+\n",
            "|     city|count|\n",
            "+---------+-----+\n",
            "|  utrecht|    4|\n",
            "|rotterdam|    4|\n",
            "|amsterdam|    2|\n",
            "+---------+-----+\n",
            "\n",
            "+---+-----+\n",
            "|age|count|\n",
            "+---+-----+\n",
            "| 21|    4|\n",
            "| 22|    3|\n",
            "| 20|    3|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getDecompFromTopFrequencies(histograms):\n",
        "  clusterlst=[]\n",
        "  for i in range(len(histograms)): #query database with top values of all columns\n",
        "    d= str(histograms[i].first()) #value of the first row\n",
        "    print(d)\n",
        "    d = d.split(\",\")[0].split('=')[1] #the splits are for formatting the string\n",
        "    print(d)\n",
        "    #print(\"d before:\",d)\n",
        "    if \"'\"  in d:\n",
        "      d = d.split(\"'\")[1]\n",
        "\n",
        "    #print(\"d after:\",d)\n",
        "    #print(type(d))\n",
        "    cname = str(histograms[i][0]).split(\"'\")[1]\n",
        "    print(cname,\"=\",d)\n",
        "    \n",
        "    data = (df.filter(col(cname) == d))\n",
        "    \n",
        "    data.show(15)\n",
        "    clusterlst.append(data)\n",
        "  return clusterlst\n",
        "\n",
        "clusterlst = getDecompFromTopFrequencies(histograms)\n"
      ],
      "metadata": {
        "id": "yQp2Ti452oGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import reduce\n",
        "from pyspark.sql.functions import lit\n",
        "from pyspark.sql import DataFrame\n",
        "def getDecompUsingFreqTable(df,freqdf): #takes original database and one frequency table as input, returns union of all queried dataframes as output\n",
        "  print(\"this is frequency table:\")\n",
        "  freqdf.show()\n",
        "  cname = freqdf.columns[0]\n",
        "  valuelist = (freqdf.select(freqdf.columns[0]).rdd.flatMap(lambda x: x).collect()) #list of all values of frequency column\n",
        "  #print(\"valuelist:\",valuelist)\n",
        "  #print(\"these are queries for the frequency table\")\n",
        "  unionlst = []\n",
        "  for v in valuelist:\n",
        "    result = df.filter(col(cname) == v)\n",
        "    query = cname + \"=\" + v\n",
        "    print(query)\n",
        "    newres=result.withColumn(\"query\",lit(query))\n",
        "    #newres.show()\n",
        "    unionlst.append(newres)\n",
        "  unn = reduce(DataFrame.unionAll, unionlst) #put all queried dataframes back together as one\n",
        "  print(\"union:\")\n",
        "  unn.show()\n",
        "\n",
        "  return unn\n",
        "\n",
        "\n",
        "union = (getDecompUsingFreqTable(df,histograms[0])) #function call with 'Name' frequency table\n",
        "print(\"equality result:\")\n",
        "subdf = are_dfs_equal(df,union.drop('query')) #checks if union of queries covers whole database\n",
        "print(subdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V1GJ4Q8lALe",
        "outputId": "d269ab52-2447-464d-8156-1796b0cac509"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "this is frequency table:\n",
            "+----+-----+\n",
            "|Name|count|\n",
            "+----+-----+\n",
            "|Nick|    4|\n",
            "|Mary|    3|\n",
            "|John|    3|\n",
            "+----+-----+\n",
            "\n",
            "Name=Nick\n",
            "Name=Mary\n",
            "Name=John\n",
            "union:\n",
            "+----+---------+---+---------+\n",
            "|Name|     city|age|    query|\n",
            "+----+---------+---+---------+\n",
            "|Nick|rotterdam| 22|Name=Nick|\n",
            "|Nick|  utrecht| 21|Name=Nick|\n",
            "|Nick|  utrecht| 20|Name=Nick|\n",
            "|Nick|amsterdam| 20|Name=Nick|\n",
            "|Mary|amsterdam| 21|Name=Mary|\n",
            "|Mary|rotterdam| 22|Name=Mary|\n",
            "|Mary|  utrecht| 22|Name=Mary|\n",
            "|John|  utrecht| 20|Name=John|\n",
            "|John|rotterdam| 21|Name=John|\n",
            "|John|rotterdam| 21|Name=John|\n",
            "+----+---------+---+---------+\n",
            "\n",
            "equality result:\n",
            "dataframes are equal\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def are_dfs_equal(df1, df2): #this works, i tested it\n",
        "  res = df1.subtract(df2) #set subtraction on the two dataframes. \n",
        "  if res.count() == 0: #subtraction yielded empty set\n",
        "    print(\"dataframes are equal\")\n",
        "    return True\n",
        "  else:\n",
        "    print(\"error! these rows are not in the union of your queries:\")\n",
        "    res.show() #show which tuples are not included in your query union\n",
        "    return False"
      ],
      "metadata": {
        "id": "fCXITpEFw6GS"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listOfFrequencyTables(clusterlst[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xxiTLKQeFX3",
        "outputId": "11b2478b-ff66-434a-9be2-9caeb3e9d1b6"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----+\n",
            "|Name|count|\n",
            "+----+-----+\n",
            "|Nick|    4|\n",
            "+----+-----+\n",
            "\n",
            "+---------+-----+\n",
            "|     city|count|\n",
            "+---------+-----+\n",
            "|  utrecht|    2|\n",
            "|amsterdam|    1|\n",
            "|rotterdam|    1|\n",
            "+---------+-----+\n",
            "\n",
            "+---+-----+\n",
            "|age|count|\n",
            "+---+-----+\n",
            "| 20|    2|\n",
            "| 22|    1|\n",
            "| 21|    1|\n",
            "+---+-----+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DataFrame[Name: string, count: bigint],\n",
              " DataFrame[city: string, count: bigint],\n",
              " DataFrame[age: int, count: bigint]]"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ignore this stuff lol\n",
        "\n",
        "'''\n",
        "  clusterlst=[]\n",
        "  for i in range(len(df)): #query database with top values of all columns\n",
        "    d= str(histograms[i].first()) #value of the first row\n",
        "    print(d)\n",
        "    d = d.split(\",\")[0].split('=')[1] #the splits are for formatting the string\n",
        "    print(d)\n",
        "    #print(\"d before:\",d)\n",
        "    if \"'\"  in d:\n",
        "      d = d.split(\"'\")[1]\n",
        "\n",
        "    #print(\"d after:\",d)\n",
        "    #print(type(d))\n",
        "    cname = str(histograms[i][0]).split(\"'\")[1]\n",
        "    print(cname,\"=\",d)\n",
        "    \n",
        "    data = (df.filter(col(cname) == d))\n",
        "    \n",
        "    data.show(15)\n",
        "    clusterlst.append(data)\n",
        "  return clusterlst\n",
        "\n",
        "clusterlst = getDecompFromTopFrequencies(histograms)\n",
        "'''\n",
        "'''\n",
        "for i in range(len(histograms)):\n",
        "  d= str(histograms[i].first()) #first row\n",
        "  d = d.split(\",\")[0].split('=')[1]\n",
        "  if \"'\"  in d:\n",
        "    d = d.split(\"'\")[1]\n",
        "  cname = str(histograms[i][0]).split(\"'\")[1] #column name\n",
        "  data = filterdf(df,cname,d)\n",
        "  data.show()\n",
        "'''"
      ],
      "metadata": {
        "id": "uJeOnVHwgt10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}