{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baselineclustering_indexedstrings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar -xvf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!java -version\n",
        "!pip install findspark"
      ],
      "metadata": {
        "id": "XxHPufpd9j3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "## You can add more config while building \n",
        "spark = SparkSession.builder.master(\"local[8]\").\\\n",
        "                    config(\"spark.app.name\",\"session_one\").\\\n",
        "                    getOrCreate() #number of threads = 16"
      ],
      "metadata": {
        "id": "viyNlUU92Ksw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = spark.read.csv(\"zomato.csv\",header=True,inferSchema=True)\n",
        "dfs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWOPnIL94c6H",
        "outputId": "d581f8d9-9dd3-4e71-cbe1-5f1d5b7bb542"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+--------------------+-------------+\n",
            "|               links|               names|ratings|             cuisine|price for one|\n",
            "+--------------------+--------------------+-------+--------------------+-------------+\n",
            "|https://www.zomat...|       Sahara Bakers|    3.7|Chinese, Bakery, ...|          100|\n",
            "|https://www.zomat...|                 KFC|    3.9|Burger, Fast Food...|          100|\n",
            "|https://www.zomat...| Subbaiah Gari Hotel|    4.1|South Indian, And...|          100|\n",
            "|https://www.zomat...|    Paradise Biryani|    3.9|Biryani, Kebab, D...|          100|\n",
            "|https://www.zomat...|  Pista House Bakery|    4.3|Fast Food, Sandwi...|          100|\n",
            "|https://www.zomat...|Shah Ghouse Hotel...|      4|North Indian, Chi...|          100|\n",
            "|https://www.zomat...|       Swagath Hotel|    4.2|South Indian, Chi...|          100|\n",
            "|https://www.zomat...|       Just Parantha|    4.2|        North Indian|          100|\n",
            "|https://www.zomat...|              Mehfil|    4.1|North Indian, Bir...|          100|\n",
            "|https://www.zomat...|         Cream Stone|    4.3| Ice Cream, Desserts|          150|\n",
            "|https://www.zomat...|  MS Bakery & Sweets|    4.3|Bakery, Desserts,...|          150|\n",
            "|https://www.zomat...|          Iqbal Cafe|    4.4| Hyderabadi, Biryani|          150|\n",
            "|https://www.zomat...|Mahalaxmi Tiffin ...|    4.1|        South Indian|          150|\n",
            "|https://www.zomat...|Al- Naseer Tahari...|    4.3|             Biryani|          150|\n",
            "|https://www.zomat...|           Pizza Hut|    3.7|Pizza, Fast Food,...|          150|\n",
            "|https://www.zomat...|    Andhra Gunpowder|    4.3|Andhra, Biryani, ...|          150|\n",
            "|https://www.zomat...|         Burger King|    4.2|   Burger, Fast Food|          150|\n",
            "|https://www.zomat...|        Kinara Grand|      4|North Indian, Chi...|          150|\n",
            "|https://www.zomat...| Meridian Restaurant|    4.1|Biryani, North In...|          150|\n",
            "|https://www.zomat...|           KS Bakers|    4.1|Bakery, Fast Food...|          150|\n",
            "+--------------------+--------------------+-------+--------------------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.schema.fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5kG2r-s4412",
        "outputId": "34d4ae2e-9174-4280-fdc8-916a11385648"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StructField(links,StringType,true),\n",
              " StructField(names,StringType,true),\n",
              " StructField(ratings,StringType,true),\n",
              " StructField(cuisine,StringType,true),\n",
              " StructField(price for one,IntegerType,true)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_cols = [c for c, t in dfs.dtypes if t =='string'] #all stringtype column names in a list\n",
        "print(string_cols)\n",
        "stringindex_cols = [(i + \"_indexed\") for i in string_cols]\n",
        "print(stringindex_cols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dcDBjpW6HW-",
        "outputId": "91488840-ded7-4af0-b419-54db169360eb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['links', 'names', 'ratings', 'cuisine']\n",
            "['links_indexed', 'names_indexed', 'ratings_indexed', 'cuisine_indexed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer  = StringIndexer( inputCols=string_cols, outputCols=stringindex_cols, handleInvalid='error', stringOrderType='frequencyDesc')\n",
        "indexer.setHandleInvalid(\"keep\")\n",
        "indexed = indexer.fit(dfs).transform(dfs)\n",
        "indexed.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpjaye667mov",
        "outputId": "b6183485-c424-42e6-c68f-4fbecce5919f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+--------------------+-------+--------------------+-------------+-------------+-------------+---------------+---------------+\n",
            "|               links|               names|ratings|             cuisine|price for one|links_indexed|names_indexed|ratings_indexed|cuisine_indexed|\n",
            "+--------------------+--------------------+-------+--------------------+-------------+-------------+-------------+---------------+---------------+\n",
            "|https://www.zomat...|       Sahara Bakers|    3.7|Chinese, Bakery, ...|          100|        472.0|        458.0|            6.0|          178.0|\n",
            "|https://www.zomat...|                 KFC|    3.9|Burger, Fast Food...|          100|        302.0|        301.0|            4.0|          141.0|\n",
            "|https://www.zomat...| Subbaiah Gari Hotel|    4.1|South Indian, And...|          100|        555.0|        537.0|            1.0|          359.0|\n",
            "|https://www.zomat...|    Paradise Biryani|    3.9|Biryani, Kebab, D...|          100|        423.0|        409.0|            4.0|          125.0|\n",
            "|https://www.zomat...|  Pista House Bakery|    4.3|Fast Food, Sandwi...|          100|        430.0|        416.0|            2.0|          232.0|\n",
            "|https://www.zomat...|Shah Ghouse Hotel...|      4|North Indian, Chi...|          100|        488.0|        474.0|            0.0|          318.0|\n",
            "|https://www.zomat...|       Swagath Hotel|    4.2|South Indian, Chi...|          100|        562.0|        544.0|            5.0|          364.0|\n",
            "|https://www.zomat...|       Just Parantha|    4.2|        North Indian|          100|        296.0|        299.0|            5.0|            5.0|\n",
            "|https://www.zomat...|              Mehfil|    4.1|North Indian, Bir...|          100|        360.0|        349.0|            1.0|          306.0|\n",
            "|https://www.zomat...|         Cream Stone|    4.3| Ice Cream, Desserts|          150|        150.0|        155.0|            2.0|            6.0|\n",
            "|https://www.zomat...|  MS Bakery & Sweets|    4.3|Bakery, Desserts,...|          150|        381.0|        333.0|            2.0|           74.0|\n",
            "|https://www.zomat...|          Iqbal Cafe|    4.4| Hyderabadi, Biryani|          150|        278.0|        281.0|           10.0|           45.0|\n",
            "|https://www.zomat...|Mahalaxmi Tiffin ...|    4.1|        South Indian|          150|        339.0|         11.0|            1.0|            0.0|\n",
            "|https://www.zomat...|Al- Naseer Tahari...|    4.3|             Biryani|          150|         27.0|         44.0|            2.0|           23.0|\n",
            "|https://www.zomat...|           Pizza Hut|    3.7|Pizza, Fast Food,...|          150|        431.0|        417.0|            6.0|          345.0|\n",
            "|https://www.zomat...|    Andhra Gunpowder|    4.3|Andhra, Biryani, ...|          150|         40.0|         57.0|            2.0|           60.0|\n",
            "|https://www.zomat...|         Burger King|    4.2|   Burger, Fast Food|          150|        102.0|        117.0|            5.0|          139.0|\n",
            "|https://www.zomat...|        Kinara Grand|      4|North Indian, Chi...|          150|        304.0|        308.0|            0.0|          308.0|\n",
            "|https://www.zomat...| Meridian Restaurant|    4.1|Biryani, North In...|          150|        361.0|        351.0|            1.0|          132.0|\n",
            "|https://www.zomat...|           KS Bakers|    4.1|Bakery, Fast Food...|          150|        319.0|        302.0|            1.0|           85.0|\n",
            "+--------------------+--------------------+-------+--------------------+-------------+-------------+-------------+---------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "allnonstringcols = [column.name for column in indexed.schema if column.dataType != StringType()]\n",
        "print(allnonstringcols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLHSwLbV80s-",
        "outputId": "53ec0bea-02db-4720-da37-0cc06ef8468d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['price for one', 'links_indexed', 'names_indexed', 'ratings_indexed', 'cuisine_indexed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "vecAssembler = VectorAssembler(outputCol=\"features\")\n",
        "vecAssembler.setInputCols(allnonstringcols)\n",
        "print(vecAssembler)\n",
        "dataset = vecAssembler.transform(indexed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo1RLeh6-CnV",
        "outputId": "f26bc6f9-a7d4-4a8f-9fc4-2524697f8fe1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VectorAssembler_6af4e5d2e936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "from pyspark.ml.clustering import KMeans\n",
        "import time\n",
        "numIterations = 100\n",
        "numberClusters = 10\n",
        "\n",
        "start = time.time()\n",
        "kmeans = KMeans().setMaxIter(numIterations).setK(numberClusters).setSeed(1)\n",
        "model = kmeans.fit(dataset)\n",
        "predictions = model.transform(dataset)\n",
        "end = time.time() - start #time taken to run kmeans and assign cluster labels to each record\n",
        "print(\"time taken to cluster with k = 10:\", end, \"seconds.\")"
      ],
      "metadata": {
        "id": "d4xFvU-X-08G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267c47e3-7592-4f74-81c9-dbb877a8553a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken to cluster with k = 10: 6.997028589248657 seconds.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#p1 = predictions.orderBy('prediction')\n",
        "#p1.show(truncate=False)\n"
      ],
      "metadata": {
        "id": "VnVbyCP6DZ0Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(p1.count())\n",
        "#dfs.count()"
      ],
      "metadata": {
        "id": "aO2ZWmnwL1Wo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.linalg import Vectors\n",
        "from pyspark.mllib.linalg.distributed import RowMatrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "zUwnV1em7-R-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F6HNRFs8adFj"
      },
      "outputs": [],
      "source": [
        "def dataframe2NumpyArray(df, colName):\n",
        "    '''\n",
        "    convert spark dataframe to numpy array\n",
        "    '''\n",
        "    return np.array(df.select(colName).collect())\n",
        "\n",
        "\n",
        "def numpyArray2Matrix(array):\n",
        "    '''\n",
        "    convert numpy array to spark Rowmatrix\n",
        "    ----------------------------\n",
        "    return: Rowmatrix\n",
        "    '''\n",
        "    if len(array.shape) == 3:\n",
        "        array.reshape((array.shape[0], array.shape[-1]))\n",
        "    \n",
        "    \n",
        "    denseVectorList = []\n",
        "    for i in range(len(array)):\n",
        "        denseVectorList.append(Vectors.dense(array[i]))\n",
        "        \n",
        "    \n",
        "    RDD = spark.sparkContext.parallelize(denseVectorList)\n",
        "    normVectors = RDD.map(lambda x: x/(np.linalg.norm(x, 2)))\n",
        "    \n",
        "    RDD = spark.sparkContext.parallelize(normVectors.collect())\n",
        "    matrix = RowMatrix(RDD)\n",
        "        \n",
        "    return matrix\n",
        "\n",
        "\n",
        "def SVDsimilarity(matrix, numDimension = 1, normalization = False):\n",
        "    '''\n",
        "    generalized cosine similarity using SVD(singular value decomposition)\n",
        "    by doing SVD, the input matrix Y will be decomposited into 3 matrix: U, S, V, with Y = USV^T\n",
        "    where S can be considered as a lower rank approximation of Y\n",
        "    the SVD optimal in the sense that minimizing the Frobinius norm of reconstruction error || \\hat{Y} - Y ||^{2}_{F}\n",
        "    therefore, by comparing the 'order K coefficient of determination' \\frac{||\\hat{Y} ||^2_F}{||Y ||^2_F}, we shall a similarity.\n",
        "    ----------------------\n",
        "    in the case of only 2 vectors, the SVD similarity is equal to the cosine similarity\n",
        "    ----------------------\n",
        "    the original SVD similarity is ranged from 1/n to 1, where n is the number of vectors\n",
        "    to get it can range over the entire [0,1] interval, one can normalize it by \\frac{}{} if only using the first sigular value\n",
        "    \n",
        "    ------------------------------------------\n",
        "    matrix: pyspark RowMatrix, represents a row-oriented distributed Matrix with no meaningful row indices\n",
        "            each column/row is an input vector\n",
        "            all element in matrix should be positive\n",
        "    numDimension: integer, if not 1 then use the first(largest) few singular value\n",
        "    normalization: if true then do normalization\n",
        "    \n",
        "    '''\n",
        "    N = matrix.numRows()\n",
        "    # SVD\n",
        "    svd = matrix.computeSVD(numDimension, computeU=False)\n",
        "    sVector = svd.s.toArray()\n",
        "    YApproximate = np.sum(sVector*sVector)**0.5\n",
        "    \n",
        "    GramianMatrix = matrix.computeGramianMatrix().toArray()\n",
        "    Y = np.trace(GramianMatrix)**0.5\n",
        "    \n",
        "    # normalization\n",
        "    if not normalization:\n",
        "        similarityScore = YApproximate/Y\n",
        "    else:\n",
        "        similarityScore = ((YApproximate/Y * N) - 1)/(N -1)\n",
        "        \n",
        "    # return 2 * similarityScore**2 - 1\n",
        "    # double angle formula\n",
        "    return 2 * similarityScore**2 - 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def crossHomogeneityScore(df, clusterColName, featureColName):\n",
        "    '''\n",
        "    \n",
        "    '''\n",
        "    if clusterColName not in df.schema.names:\n",
        "        \n",
        "        npArray = dataframe2NumpyArray(df, featureColName)\n",
        "        matrix = numpyArray2Matrix(npArray)\n",
        "        similarity = SVDsimilarity(matrix)\n",
        "        \n",
        "        return similarity\n",
        "    \n",
        "    \n",
        "    totalRows = df.count()\n",
        "    queries = list(set(df.select(clusterColName).collect()))\n",
        "    \n",
        "    homogeneityScore = 0\n",
        "    \n",
        "    for query in queries:\n",
        "        # get each cluster\n",
        "        dfQuery = df.filter(df[clusterColName] == query.query)\n",
        "        # get number of rows\n",
        "        numRows = dfQuery.count()\n",
        "        \n",
        "        npArray = dataframe2NumpyArray(dfQuery, featureColName)\n",
        "        matrix = numpyArray2Matrix(npArray)\n",
        "        \n",
        "        similarity = SVDsimilarity(matrix)\n",
        "        homogeneityScore += similarity * numRows/totalRows\n",
        "    \n",
        "    return homogeneityScore"
      ],
      "metadata": {
        "id": "yANK1djLdZR5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calcstart = time.time()\n",
        "score = crossHomogeneityScore(predictions, 'predictions', 'features')\n",
        "calcend = time.time() - calcstart\n",
        "print(\"homog score:\", score)\n",
        "print(\"time taken to calculate homogeneity:\", calcend, \"seconds.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCei2_FYe1Gz",
        "outputId": "fafd3f28-cb3f-4097-e57e-313f22a4d575"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "homog score: 0.632042901742482\n",
            "time taken to calculate homogeneity: 1.453683853149414 seconds.\n"
          ]
        }
      ]
    }
  ]
}