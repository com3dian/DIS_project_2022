{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"SPARK_HOME\"] = \"/home/com3dian/Documents/github/Period4/DIS/spark-3.2.1-bin-hadoop3.2\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "## You can add more config while building \n",
    "spark = SparkSession.builder.master(\"local[16]\").\\\n",
    "                    config(\"spark.app.name\",\"session_one\").\\\n",
    "                    getOrCreate() #number of threads = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.linalg.distributed import RowMatrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe2NumpyArray(df, colName):\n",
    "    '''\n",
    "    convert spark dataframe to numpy array\n",
    "    '''\n",
    "    return np.array(df.select(colName).collect())\n",
    "\n",
    "\n",
    "def numpyArray2Matrix(array):\n",
    "    '''\n",
    "    convert numpy array to spark Rowmatrix\n",
    "    ----------------------------\n",
    "    return: Rowmatrix\n",
    "    '''\n",
    "    if len(array.shape) == 3:\n",
    "        array.reshape((array.shape[0], array.shape[-1]))\n",
    "    \n",
    "    \n",
    "    denseVectorList = []\n",
    "    for i in range(len(array)):\n",
    "        denseVectorList.append(Vectors.dense(array[i]))\n",
    "        \n",
    "    \n",
    "    RDD = spark.sparkContext.parallelize(denseVectorList)\n",
    "    normVectors = RDD.map(lambda x: x/(np.linalg.norm(x, 2)))\n",
    "    \n",
    "    RDD = spark.sparkContext.parallelize(normVectors.collect())\n",
    "    matrix = RowMatrix(RDD)\n",
    "        \n",
    "    return matrix\n",
    "\n",
    "\n",
    "def SVDsimilarity(matrix, numDimension = 1, normalization = False):\n",
    "    '''\n",
    "    generalized cosine similarity using SVD(singular value decomposition)\n",
    "    by doing SVD, the input matrix Y will be decomposited into 3 matrix: U, S, V, with Y = USV^T\n",
    "    where S can be considered as a lower rank approximation of Y\n",
    "    the SVD optimal in the sense that minimizing the Frobinius norm of reconstruction error || \\hat{Y} - Y ||^{2}_{F}\n",
    "    therefore, by comparing the 'order K coefficient of determination' \\frac{||\\hat{Y} ||^2_F}{||Y ||^2_F}, we shall a similarity.\n",
    "    ----------------------\n",
    "    in the case of only 2 vectors, the SVD similarity is equal to the cosine similarity\n",
    "    ----------------------\n",
    "    the original SVD similarity is ranged from 1/n to 1, where n is the number of vectors\n",
    "    to get it can range over the entire [0,1] interval, one can normalize it by \\frac{}{} if only using the first sigular value\n",
    "    \n",
    "    ------------------------------------------\n",
    "    matrix: pyspark RowMatrix, represents a row-oriented distributed Matrix with no meaningful row indices\n",
    "            each column/row is an input vector\n",
    "            all element in matrix should be positive\n",
    "    numDimension: integer, if not 1 then use the first(largest) few singular value\n",
    "    normalization: if true then do normalization\n",
    "    \n",
    "    '''\n",
    "    N = matrix.numRows()\n",
    "    # SVD\n",
    "    svd = matrix.computeSVD(numDimension, computeU=False)\n",
    "    sVector = svd.s.toArray()\n",
    "    YApproximate = np.sum(sVector*sVector)**0.5\n",
    "    \n",
    "    GramianMatrix = matrix.computeGramianMatrix().toArray()\n",
    "    Y = np.trace(GramianMatrix)**0.5\n",
    "    \n",
    "    # normalization\n",
    "    if not normalization:\n",
    "        similarityScore = YApproximate/Y\n",
    "    else:\n",
    "        similarityScore = ((YApproximate/Y * N) - 1)/(N -1)\n",
    "        \n",
    "    # return 2 * similarityScore**2 - 1\n",
    "    # double angle formula\n",
    "    return 2 * similarityScore**2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def crossHomogeneityScore(df, queryColName, featureColName):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    if queryColName not in df.schema.names:\n",
    "        \n",
    "        npArray = dataframe2NumpyArray(df, featureColName)\n",
    "        matrix = numpyArray2Matrix(npArray)\n",
    "        similarity = SVDsimilarity(matrix)\n",
    "        return similarity\n",
    "    \n",
    "    totalRows = df.count()\n",
    "    queries = list(set(df.select(queryColName).collect()))\n",
    "    homogeneityScore = 0\n",
    "    \n",
    "    for query in tqdm(queries):\n",
    "        # get each cluster\n",
    "        dfQuery = df.filter(df[queryColName] == query.query)\n",
    "        # get number of rows\n",
    "        numRows = dfQuery.count()\n",
    "        npArray = dataframe2NumpyArray(dfQuery, featureColName)\n",
    "        matrix = numpyArray2Matrix(npArray)\n",
    "        similarity = SVDsimilarity(matrix)\n",
    "        homogeneityScore += similarity * numRows/totalRows\n",
    "    \n",
    "    return homogeneityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "def listOfFrequencyTables(df): #take main dataframe, generate frequency dataframes\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    histograms = []\n",
    "    for col in df.dtypes:\n",
    "        h=df.groupBy(col[0]).count()\n",
    "        h = h.sort(desc(\"count\"))\n",
    "        histograms.append(h)\n",
    "    return histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDecompFromTopFrequencies(df, histograms):\n",
    "    clusterlst=[]\n",
    "    for i in range(len(histograms)): #query database with top values of all columns\n",
    "        d= str(histograms[i].first()) #value of the first row\n",
    "        #print(d)\n",
    "        d = d.split(\",\")[0].split('=')[1] #the splits are for formatting the string\n",
    "        #print(d)\n",
    "        #print(\"d before:\",d)\n",
    "        if \"'\"  in d:\n",
    "            d = d.split(\"'\")[1]\n",
    "        \n",
    "        #print(\"d after:\",d)\n",
    "        #print(type(d))\n",
    "        cname = str(histograms[i][0]).split(\"'\")[1]\n",
    "        data = (df.filter(col(cname) == d))\n",
    "        clusterlst.append(data)\n",
    "    return clusterlst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_dfs_equal(df1, df2): #this works, i tested it\n",
    "    res = df1.subtract(df2) #set subtraction on the two dataframes. \n",
    "    if res.count() == 0: #subtraction yielded empty set\n",
    "        print(\"dataframes are equal\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"error! these rows are not in the union of your queries:\")\n",
    "        res.show() #show which tuples are not included in your query union\n",
    "        return False\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import DataFrame\n",
    "from tqdm import tqdm\n",
    "\n",
    "def getDecompUsingFreqTable(df, freqdf):\n",
    "    colName = freqdf.columns[0]\n",
    "    \n",
    "    df = df.withColumn('new_query_1', lit(colName))\n",
    "    df = df.withColumn('new_query', concat_ws(' = ', 'new_query_1', colName))\n",
    "    df = df.drop('new_query_1')\n",
    "    \n",
    "    if 'query' in df.columns:\n",
    "        df = df.withColumn('new_query', concat_ws(', ', 'new_query', 'query'))\n",
    "        df = df.drop('query')\n",
    "    df = df.withColumnRenamed('new_query', 'query')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFeatureVector(df): #get feature vector for any dataframe for homogeneity function\n",
    "    string_cols = [c for c, t in df.dtypes if t =='string' and c != 'query'] #get all columns that have stringtype, except query column\n",
    "    \n",
    "    stringindex_cols = [(i + \"_indexed\") for i in string_cols]\n",
    "    indexer  = StringIndexer( inputCols=string_cols, outputCols=stringindex_cols, handleInvalid='error', stringOrderType='frequencyDesc')\n",
    "    indexer.setHandleInvalid(\"skip\") #change to \"skip\" to remove problematic rows\n",
    "    indexed = indexer.fit(df).transform(df) #dataframe with indexed columns attached\n",
    "    \n",
    "    allnonstringcols = [column.name for column in indexed.schema if column.dataType != StringType()]\n",
    "    vecAssembler = VectorAssembler(outputCol=\"features\")\n",
    "    \n",
    "    # normalizaing\n",
    "    # for col in allnonstringcols:\n",
    "    #    maxValue = indexed.agg({col: \"max\"}).collect()[0][0]\n",
    "    #    print(maxValue)\n",
    "    #    minValue = indexed.agg({col: \"min\"}).collect()[0][0]\n",
    "    #    print(minValue)\n",
    "    #    indexed = indexed.withColumn(col + '_normalized', (indexed[col] - minValue)/(maxValue - minValue + 0.001*minValue))\n",
    "    #    print(indexed.columns)\n",
    "    # allnonstringcols = [col + '_normalized' for col in allnonstringcols]\n",
    "    print(allnonstringcols)\n",
    "    vecAssembler.setInputCols(allnonstringcols) #all numerical columns are put into feature vector, including indexed cols\n",
    "    result = ( vecAssembler.transform(indexed)) #return the dataframe with feature column attached\n",
    "    # for col in allnonstringcols:\n",
    "    #    result = result.drop(col)\n",
    "    for col in stringindex_cols:\n",
    "        result = result.drop(col)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def shuffle(hist):\n",
    "    return sorted(hist, key = lambda x: x.count())\n",
    "\n",
    "def getDecompositionbyColumn(df, K):\n",
    "    histograms = shuffle(listOfFrequencyTables(df))\n",
    "    histList = list(range(len(histograms)))\n",
    "    colLeft = len(histograms)\n",
    "    \n",
    "    decomUnionWithVec = addFeatureVector(df)\n",
    "    decomUnionWithVec.show()\n",
    "    decomUnionWithVec.select('features').show(decomUnionWithVec.count(), False)\n",
    "    overAllHomoScore = crossHomogeneityScore(decomUnionWithVec, 'query', 'features')\n",
    "    print('over all homogeneity score: ', overAllHomoScore)\n",
    "    \n",
    "    nBucketsBefore = 1\n",
    "    crossScoreBefore = overAllHomoScore\n",
    "    \n",
    "    update = True\n",
    "    \n",
    "    while update:\n",
    "        if nBucketsBefore >= K or colLeft == 0:\n",
    "\n",
    "            break\n",
    "        \n",
    "        \n",
    "        update = False\n",
    "        removeIndex = -1\n",
    "        \n",
    "        for i in histList:\n",
    "            freqdf = histograms[i]\n",
    "            \n",
    "            unionWithVec = getDecompUsingFreqTable(decomUnionWithVec, freqdf)\n",
    "            nBucketsAfter = unionWithVec.select('query').distinct().count()\n",
    "            \n",
    "            if nBucketsAfter == nBucketsBefore or nBucketsAfter > K:\n",
    "                continue\n",
    "            \n",
    "            crossScoreAfter = crossHomogeneityScore(unionWithVec, 'query', 'features')\n",
    "            if crossScoreAfter > crossScoreBefore :\n",
    "                \n",
    "                # update using new decomposition\n",
    "                \n",
    "                crossScoreBefore = crossScoreAfter\n",
    "                \n",
    "                removeIndex = i \n",
    "                update = True\n",
    "                \n",
    "        histList = [_ for _ in histList if _ != removeIndex]\n",
    "        colLeft = len(histList)\n",
    "        \n",
    "        if update:\n",
    "            \n",
    "            decomUnionWithVec = getDecompUsingFreqTable(decomUnionWithVec, histograms[removeIndex])\n",
    "            nBucketsBefore = decomUnionWithVec.select('query').distinct().count()\n",
    "        \n",
    "    if 'query' not in decomUnionWithVec.columns:\n",
    "        print('user requested K =', str(K), ', but we can only got ', str(1), 'clusters.') \n",
    "        return decomUnionWithVec.drop('features')\n",
    "    \n",
    "    if nBucketsBefore != K:\n",
    "        print('user requested K =', str(K), ', but we can only got ', str(nBucketsBefore), 'clusters.') \n",
    "    return decomUnionWithVec.drop('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "|LatD| \"LatM\"| \"LatS\"| \"NS\"| \"LonD\"| \"LonM\"| \"LonS\"| \"EW\"|            \"City\"| \"State\"|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "|41.0|    5.0|   59.0|  \"N\"|   80.0|   39.0|    0.0|  \"W\"|      \"Youngstown\"|      OH|\n",
      "|42.0|   52.0|   48.0|  \"N\"|   97.0|   23.0|   23.0|  \"W\"|         \"Yankton\"|      SD|\n",
      "|46.0|   35.0|   59.0|  \"N\"|  120.0|   30.0|   36.0|  \"W\"|          \"Yakima\"|      WA|\n",
      "|42.0|   16.0|   12.0|  \"N\"|   71.0|   48.0|    0.0|  \"W\"|       \"Worcester\"|      MA|\n",
      "|43.0|   37.0|   48.0|  \"N\"|   89.0|   46.0|   11.0|  \"W\"| \"Wisconsin Dells\"|      WI|\n",
      "|36.0|    5.0|   59.0|  \"N\"|   80.0|   15.0|    0.0|  \"W\"|   \"Winston-Salem\"|      NC|\n",
      "|49.0|   52.0|   48.0|  \"N\"|   97.0|    9.0|    0.0|  \"W\"|        \"Winnipeg\"|      MB|\n",
      "|39.0|   11.0|   23.0|  \"N\"|   78.0|    9.0|   36.0|  \"W\"|      \"Winchester\"|      VA|\n",
      "|34.0|   14.0|   24.0|  \"N\"|   77.0|   55.0|   11.0|  \"W\"|      \"Wilmington\"|      NC|\n",
      "|39.0|   45.0|    0.0|  \"N\"|   75.0|   33.0|    0.0|  \"W\"|      \"Wilmington\"|      DE|\n",
      "|48.0|    9.0|    0.0|  \"N\"|  103.0|   37.0|   12.0|  \"W\"|       \"Williston\"|      ND|\n",
      "|41.0|   15.0|    0.0|  \"N\"|   77.0|    0.0|    0.0|  \"W\"|    \"Williamsport\"|      PA|\n",
      "|37.0|   40.0|   48.0|  \"N\"|   82.0|   16.0|   47.0|  \"W\"|      \"Williamson\"|      WV|\n",
      "|33.0|   54.0|    0.0|  \"N\"|   98.0|   29.0|   23.0|  \"W\"|   \"Wichita Falls\"|      TX|\n",
      "|37.0|   41.0|   23.0|  \"N\"|   97.0|   20.0|   23.0|  \"W\"|         \"Wichita\"|      KS|\n",
      "|40.0|    4.0|   11.0|  \"N\"|   80.0|   43.0|   12.0|  \"W\"|        \"Wheeling\"|      WV|\n",
      "|26.0|   43.0|   11.0|  \"N\"|   80.0|    3.0|    0.0|  \"W\"| \"West Palm Beach\"|      FL|\n",
      "|47.0|   25.0|   11.0|  \"N\"|  120.0|   19.0|   11.0|  \"W\"|       \"Wenatchee\"|      WA|\n",
      "|41.0|   25.0|   11.0|  \"N\"|  122.0|   23.0|   23.0|  \"W\"|            \"Weed\"|      CA|\n",
      "|31.0|   13.0|   11.0|  \"N\"|   82.0|   20.0|   59.0|  \"W\"|        \"Waycross\"|      GA|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"/home/com3dian/Documents/github/DIS_project_2022/data/cities.csv\",header=True,inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LatD', ' \"LatM\"', ' \"LatS\"', ' \"LonD\"', ' \"LonM\"', ' \"LonS\"', ' \"NS\"_indexed', ' \"EW\"_indexed', ' \"City\"_indexed', ' \"State\"_indexed']\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+-------------+-------------+---------------+----------------+--------------------+\n",
      "|LatD| \"LatM\"| \"LatS\"| \"NS\"| \"LonD\"| \"LonM\"| \"LonS\"| \"EW\"|            \"City\"| \"State\"| \"NS\"_indexed| \"EW\"_indexed| \"City\"_indexed| \"State\"_indexed|            features|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+-------------+-------------+---------------+----------------+--------------------+\n",
      "|41.0|    5.0|   59.0|  \"N\"|   80.0|   39.0|    0.0|  \"W\"|      \"Youngstown\"|      OH|          0.0|          0.0|          119.0|             6.0|[41.0,5.0,59.0,80...|\n",
      "|42.0|   52.0|   48.0|  \"N\"|   97.0|   23.0|   23.0|  \"W\"|         \"Yankton\"|      SD|          0.0|          0.0|          118.0|            18.0|[42.0,52.0,48.0,9...|\n",
      "|46.0|   35.0|   59.0|  \"N\"|  120.0|   30.0|   36.0|  \"W\"|          \"Yakima\"|      WA|          0.0|          0.0|          117.0|             3.0|[46.0,35.0,59.0,1...|\n",
      "|42.0|   16.0|   12.0|  \"N\"|   71.0|   48.0|    0.0|  \"W\"|       \"Worcester\"|      MA|          0.0|          0.0|          116.0|            21.0|[42.0,16.0,12.0,7...|\n",
      "|43.0|   37.0|   48.0|  \"N\"|   89.0|   46.0|   11.0|  \"W\"| \"Wisconsin Dells\"|      WI|          0.0|          0.0|          115.0|            12.0|[43.0,37.0,48.0,8...|\n",
      "|36.0|    5.0|   59.0|  \"N\"|   80.0|   15.0|    0.0|  \"W\"|   \"Winston-Salem\"|      NC|          0.0|          0.0|          114.0|            17.0|[36.0,5.0,59.0,80...|\n",
      "|49.0|   52.0|   48.0|  \"N\"|   97.0|    9.0|    0.0|  \"W\"|        \"Winnipeg\"|      MB|          0.0|          0.0|          113.0|            37.0|[49.0,52.0,48.0,9...|\n",
      "|39.0|   11.0|   23.0|  \"N\"|   78.0|    9.0|   36.0|  \"W\"|      \"Winchester\"|      VA|          0.0|          0.0|          112.0|            11.0|[39.0,11.0,23.0,7...|\n",
      "|34.0|   14.0|   24.0|  \"N\"|   77.0|   55.0|   11.0|  \"W\"|      \"Wilmington\"|      NC|          0.0|          0.0|            5.0|            17.0|[34.0,14.0,24.0,7...|\n",
      "|39.0|   45.0|    0.0|  \"N\"|   75.0|   33.0|    0.0|  \"W\"|      \"Wilmington\"|      DE|          0.0|          0.0|            5.0|            34.0|[39.0,45.0,0.0,75...|\n",
      "|48.0|    9.0|    0.0|  \"N\"|  103.0|   37.0|   12.0|  \"W\"|       \"Williston\"|      ND|          0.0|          0.0|          111.0|            23.0|[48.0,9.0,0.0,103...|\n",
      "|41.0|   15.0|    0.0|  \"N\"|   77.0|    0.0|    0.0|  \"W\"|    \"Williamsport\"|      PA|          0.0|          0.0|          110.0|             2.0|(10,[0,1,3,8,9],[...|\n",
      "|37.0|   40.0|   48.0|  \"N\"|   82.0|   16.0|   47.0|  \"W\"|      \"Williamson\"|      WV|          0.0|          0.0|          109.0|            28.0|[37.0,40.0,48.0,8...|\n",
      "|33.0|   54.0|    0.0|  \"N\"|   98.0|   29.0|   23.0|  \"W\"|   \"Wichita Falls\"|      TX|          0.0|          0.0|          107.0|             1.0|[33.0,54.0,0.0,98...|\n",
      "|37.0|   41.0|   23.0|  \"N\"|   97.0|   20.0|   23.0|  \"W\"|         \"Wichita\"|      KS|          0.0|          0.0|          108.0|            15.0|[37.0,41.0,23.0,9...|\n",
      "|40.0|    4.0|   11.0|  \"N\"|   80.0|   43.0|   12.0|  \"W\"|        \"Wheeling\"|      WV|          0.0|          0.0|          106.0|            28.0|[40.0,4.0,11.0,80...|\n",
      "|26.0|   43.0|   11.0|  \"N\"|   80.0|    3.0|    0.0|  \"W\"| \"West Palm Beach\"|      FL|          0.0|          0.0|          105.0|             4.0|[26.0,43.0,11.0,8...|\n",
      "|47.0|   25.0|   11.0|  \"N\"|  120.0|   19.0|   11.0|  \"W\"|       \"Wenatchee\"|      WA|          0.0|          0.0|          104.0|             3.0|[47.0,25.0,11.0,1...|\n",
      "|41.0|   25.0|   11.0|  \"N\"|  122.0|   23.0|   23.0|  \"W\"|            \"Weed\"|      CA|          0.0|          0.0|          103.0|             0.0|[41.0,25.0,11.0,1...|\n",
      "|31.0|   13.0|   11.0|  \"N\"|   82.0|   20.0|   59.0|  \"W\"|        \"Waycross\"|      GA|          0.0|          0.0|          102.0|             7.0|[31.0,13.0,11.0,8...|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+-------------+-------------+---------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+--------------------+\n",
      "|LatD| \"LatM\"| \"LatS\"| \"NS\"| \"LonD\"| \"LonM\"| \"LonS\"| \"EW\"|            \"City\"| \"State\"|            features|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+--------------------+\n",
      "|41.0|    5.0|   59.0|  \"N\"|   80.0|   39.0|    0.0|  \"W\"|      \"Youngstown\"|      OH|[41.0,5.0,59.0,80...|\n",
      "|42.0|   52.0|   48.0|  \"N\"|   97.0|   23.0|   23.0|  \"W\"|         \"Yankton\"|      SD|[42.0,52.0,48.0,9...|\n",
      "|46.0|   35.0|   59.0|  \"N\"|  120.0|   30.0|   36.0|  \"W\"|          \"Yakima\"|      WA|[46.0,35.0,59.0,1...|\n",
      "|42.0|   16.0|   12.0|  \"N\"|   71.0|   48.0|    0.0|  \"W\"|       \"Worcester\"|      MA|[42.0,16.0,12.0,7...|\n",
      "|43.0|   37.0|   48.0|  \"N\"|   89.0|   46.0|   11.0|  \"W\"| \"Wisconsin Dells\"|      WI|[43.0,37.0,48.0,8...|\n",
      "|36.0|    5.0|   59.0|  \"N\"|   80.0|   15.0|    0.0|  \"W\"|   \"Winston-Salem\"|      NC|[36.0,5.0,59.0,80...|\n",
      "|49.0|   52.0|   48.0|  \"N\"|   97.0|    9.0|    0.0|  \"W\"|        \"Winnipeg\"|      MB|[49.0,52.0,48.0,9...|\n",
      "|39.0|   11.0|   23.0|  \"N\"|   78.0|    9.0|   36.0|  \"W\"|      \"Winchester\"|      VA|[39.0,11.0,23.0,7...|\n",
      "|34.0|   14.0|   24.0|  \"N\"|   77.0|   55.0|   11.0|  \"W\"|      \"Wilmington\"|      NC|[34.0,14.0,24.0,7...|\n",
      "|39.0|   45.0|    0.0|  \"N\"|   75.0|   33.0|    0.0|  \"W\"|      \"Wilmington\"|      DE|[39.0,45.0,0.0,75...|\n",
      "|48.0|    9.0|    0.0|  \"N\"|  103.0|   37.0|   12.0|  \"W\"|       \"Williston\"|      ND|[48.0,9.0,0.0,103...|\n",
      "|41.0|   15.0|    0.0|  \"N\"|   77.0|    0.0|    0.0|  \"W\"|    \"Williamsport\"|      PA|(10,[0,1,3,8,9],[...|\n",
      "|37.0|   40.0|   48.0|  \"N\"|   82.0|   16.0|   47.0|  \"W\"|      \"Williamson\"|      WV|[37.0,40.0,48.0,8...|\n",
      "|33.0|   54.0|    0.0|  \"N\"|   98.0|   29.0|   23.0|  \"W\"|   \"Wichita Falls\"|      TX|[33.0,54.0,0.0,98...|\n",
      "|37.0|   41.0|   23.0|  \"N\"|   97.0|   20.0|   23.0|  \"W\"|         \"Wichita\"|      KS|[37.0,41.0,23.0,9...|\n",
      "|40.0|    4.0|   11.0|  \"N\"|   80.0|   43.0|   12.0|  \"W\"|        \"Wheeling\"|      WV|[40.0,4.0,11.0,80...|\n",
      "|26.0|   43.0|   11.0|  \"N\"|   80.0|    3.0|    0.0|  \"W\"| \"West Palm Beach\"|      FL|[26.0,43.0,11.0,8...|\n",
      "|47.0|   25.0|   11.0|  \"N\"|  120.0|   19.0|   11.0|  \"W\"|       \"Wenatchee\"|      WA|[47.0,25.0,11.0,1...|\n",
      "|41.0|   25.0|   11.0|  \"N\"|  122.0|   23.0|   23.0|  \"W\"|            \"Weed\"|      CA|[41.0,25.0,11.0,1...|\n",
      "|31.0|   13.0|   11.0|  \"N\"|   82.0|   20.0|   59.0|  \"W\"|        \"Waycross\"|      GA|[31.0,13.0,11.0,8...|\n",
      "+----+-------+-------+-----+-------+-------+-------+-----+------------------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------------------------------------+\n",
      "|features                                          |\n",
      "+--------------------------------------------------+\n",
      "|[41.0,5.0,59.0,80.0,39.0,0.0,0.0,0.0,119.0,6.0]   |\n",
      "|[42.0,52.0,48.0,97.0,23.0,23.0,0.0,0.0,118.0,18.0]|\n",
      "|[46.0,35.0,59.0,120.0,30.0,36.0,0.0,0.0,117.0,3.0]|\n",
      "|[42.0,16.0,12.0,71.0,48.0,0.0,0.0,0.0,116.0,21.0] |\n",
      "|[43.0,37.0,48.0,89.0,46.0,11.0,0.0,0.0,115.0,12.0]|\n",
      "|[36.0,5.0,59.0,80.0,15.0,0.0,0.0,0.0,114.0,17.0]  |\n",
      "|[49.0,52.0,48.0,97.0,9.0,0.0,0.0,0.0,113.0,37.0]  |\n",
      "|[39.0,11.0,23.0,78.0,9.0,36.0,0.0,0.0,112.0,11.0] |\n",
      "|[34.0,14.0,24.0,77.0,55.0,11.0,0.0,0.0,5.0,17.0]  |\n",
      "|[39.0,45.0,0.0,75.0,33.0,0.0,0.0,0.0,5.0,34.0]    |\n",
      "|[48.0,9.0,0.0,103.0,37.0,12.0,0.0,0.0,111.0,23.0] |\n",
      "|(10,[0,1,3,8,9],[41.0,15.0,77.0,110.0,2.0])       |\n",
      "|[37.0,40.0,48.0,82.0,16.0,47.0,0.0,0.0,109.0,28.0]|\n",
      "|[33.0,54.0,0.0,98.0,29.0,23.0,0.0,0.0,107.0,1.0]  |\n",
      "|[37.0,41.0,23.0,97.0,20.0,23.0,0.0,0.0,108.0,15.0]|\n",
      "|[40.0,4.0,11.0,80.0,43.0,12.0,0.0,0.0,106.0,28.0] |\n",
      "|[26.0,43.0,11.0,80.0,3.0,0.0,0.0,0.0,105.0,4.0]   |\n",
      "|[47.0,25.0,11.0,120.0,19.0,11.0,0.0,0.0,104.0,3.0]|\n",
      "|[41.0,25.0,11.0,122.0,23.0,23.0,0.0,0.0,103.0,0.0]|\n",
      "|[31.0,13.0,11.0,82.0,20.0,59.0,0.0,0.0,102.0,7.0] |\n",
      "|[44.0,57.0,35.0,89.0,38.0,23.0,0.0,0.0,101.0,12.0]|\n",
      "|[42.0,21.0,36.0,87.0,49.0,48.0,0.0,0.0,100.0,14.0]|\n",
      "|[44.0,54.0,0.0,97.0,6.0,36.0,0.0,0.0,4.0,18.0]    |\n",
      "|[43.0,58.0,47.0,75.0,55.0,11.0,0.0,0.0,4.0,5.0]   |\n",
      "|[42.0,30.0,0.0,92.0,20.0,23.0,0.0,0.0,99.0,20.0]  |\n",
      "|[41.0,32.0,59.0,73.0,3.0,0.0,0.0,0.0,98.0,32.0]   |\n",
      "|[38.0,53.0,23.0,77.0,1.0,47.0,0.0,0.0,97.0,33.0]  |\n",
      "|[41.0,50.0,59.0,79.0,8.0,23.0,0.0,0.0,96.0,2.0]   |\n",
      "|[46.0,4.0,11.0,118.0,19.0,48.0,0.0,0.0,95.0,3.0]  |\n",
      "|[31.0,32.0,59.0,97.0,8.0,23.0,0.0,0.0,94.0,1.0]   |\n",
      "|[38.0,40.0,48.0,87.0,31.0,47.0,0.0,0.0,93.0,8.0]  |\n",
      "|[28.0,48.0,35.0,97.0,0.0,36.0,0.0,0.0,92.0,1.0]   |\n",
      "|[32.0,20.0,59.0,90.0,52.0,47.0,0.0,0.0,91.0,22.0] |\n",
      "|[49.0,16.0,12.0,123.0,7.0,12.0,0.0,0.0,90.0,31.0] |\n",
      "|[46.0,55.0,11.0,98.0,0.0,36.0,0.0,0.0,89.0,23.0]  |\n",
      "|[30.0,49.0,47.0,83.0,16.0,47.0,0.0,0.0,88.0,7.0]  |\n",
      "|[43.0,6.0,36.0,75.0,13.0,48.0,0.0,0.0,87.0,5.0]   |\n",
      "|[39.0,54.0,0.0,79.0,43.0,48.0,0.0,0.0,86.0,2.0]   |\n",
      "|[32.0,20.0,59.0,95.0,18.0,0.0,0.0,0.0,85.0,1.0]   |\n",
      "|[42.0,33.0,36.0,114.0,28.0,12.0,0.0,0.0,84.0,35.0]|\n",
      "|[33.0,12.0,35.0,87.0,34.0,11.0,0.0,0.0,83.0,19.0] |\n",
      "|[34.0,15.0,35.0,88.0,42.0,35.0,0.0,0.0,82.0,22.0] |\n",
      "|[36.0,9.0,35.0,95.0,54.0,36.0,0.0,0.0,81.0,25.0]  |\n",
      "|[32.0,13.0,12.0,110.0,58.0,12.0,0.0,0.0,80.0,30.0]|\n",
      "|[37.0,10.0,11.0,104.0,30.0,36.0,0.0,0.0,79.0,13.0]|\n",
      "|[40.0,13.0,47.0,74.0,46.0,11.0,0.0,0.0,78.0,40.0] |\n",
      "|[44.0,45.0,35.0,85.0,37.0,47.0,0.0,0.0,77.0,9.0]  |\n",
      "|[43.0,39.0,0.0,79.0,22.0,47.0,0.0,0.0,76.0,43.0]  |\n",
      "|[39.0,2.0,59.0,95.0,40.0,11.0,0.0,0.0,75.0,15.0]  |\n",
      "|[41.0,39.0,0.0,83.0,32.0,24.0,0.0,0.0,74.0,6.0]   |\n",
      "|[33.0,25.0,48.0,94.0,3.0,0.0,0.0,0.0,73.0,1.0]    |\n",
      "|[39.0,28.0,12.0,87.0,24.0,36.0,0.0,0.0,72.0,8.0]  |\n",
      "|[27.0,57.0,0.0,82.0,26.0,59.0,0.0,0.0,71.0,4.0]   |\n",
      "|[30.0,27.0,0.0,84.0,16.0,47.0,0.0,0.0,70.0,4.0]   |\n",
      "|[47.0,14.0,24.0,122.0,25.0,48.0,0.0,0.0,69.0,3.0] |\n",
      "|[43.0,2.0,59.0,76.0,9.0,0.0,0.0,0.0,68.0,5.0]     |\n",
      "|[32.0,35.0,59.0,82.0,20.0,23.0,0.0,0.0,67.0,7.0]  |\n",
      "|[33.0,55.0,11.0,80.0,20.0,59.0,0.0,0.0,66.0,46.0] |\n",
      "|[40.0,59.0,24.0,75.0,11.0,24.0,0.0,0.0,65.0,2.0]  |\n",
      "|[37.0,57.0,35.0,121.0,17.0,24.0,0.0,0.0,64.0,0.0] |\n",
      "|[44.0,31.0,12.0,89.0,34.0,11.0,0.0,0.0,63.0,12.0] |\n",
      "|[40.0,21.0,36.0,80.0,37.0,12.0,0.0,0.0,62.0,6.0]  |\n",
      "|[40.0,37.0,11.0,103.0,13.0,12.0,0.0,0.0,61.0,13.0]|\n",
      "|[38.0,9.0,0.0,79.0,4.0,11.0,0.0,0.0,60.0,11.0]    |\n",
      "|[39.0,55.0,11.0,83.0,48.0,35.0,0.0,0.0,0.0,6.0]   |\n",
      "|[37.0,13.0,12.0,93.0,17.0,24.0,0.0,0.0,0.0,10.0]  |\n",
      "|[42.0,5.0,59.0,72.0,35.0,23.0,0.0,0.0,0.0,21.0]   |\n",
      "|[39.0,47.0,59.0,89.0,39.0,0.0,0.0,0.0,0.0,14.0]   |\n",
      "|[47.0,40.0,11.0,117.0,24.0,36.0,0.0,0.0,59.0,3.0] |\n",
      "|[41.0,40.0,48.0,86.0,15.0,0.0,0.0,0.0,58.0,8.0]   |\n",
      "|[43.0,32.0,24.0,96.0,43.0,48.0,0.0,0.0,57.0,18.0] |\n",
      "|[42.0,29.0,24.0,96.0,23.0,23.0,0.0,0.0,56.0,20.0] |\n",
      "|[32.0,30.0,35.0,93.0,45.0,0.0,0.0,0.0,55.0,36.0]  |\n",
      "|[33.0,38.0,23.0,96.0,36.0,36.0,0.0,0.0,54.0,1.0]  |\n",
      "|[44.0,47.0,59.0,106.0,57.0,35.0,0.0,0.0,53.0,29.0]|\n",
      "|[35.0,13.0,47.0,96.0,40.0,48.0,0.0,0.0,52.0,25.0] |\n",
      "|[32.0,25.0,11.0,87.0,1.0,11.0,0.0,0.0,51.0,19.0]  |\n",
      "|[38.0,42.0,35.0,93.0,13.0,48.0,0.0,0.0,50.0,10.0] |\n",
      "|[47.0,35.0,59.0,122.0,19.0,48.0,0.0,0.0,49.0,3.0] |\n",
      "|[41.0,24.0,35.0,75.0,40.0,11.0,0.0,0.0,48.0,2.0]  |\n",
      "|[41.0,52.0,11.0,103.0,39.0,36.0,0.0,0.0,47.0,39.0]|\n",
      "|[42.0,49.0,11.0,73.0,56.0,59.0,0.0,0.0,46.0,5.0]  |\n",
      "|[32.0,4.0,48.0,81.0,5.0,23.0,0.0,0.0,45.0,7.0]    |\n",
      "|[46.0,29.0,24.0,84.0,20.0,59.0,0.0,0.0,44.0,9.0]  |\n",
      "|[27.0,20.0,24.0,82.0,31.0,47.0,0.0,0.0,43.0,4.0]  |\n",
      "|[38.0,26.0,23.0,122.0,43.0,12.0,0.0,0.0,42.0,0.0] |\n",
      "|[35.0,40.0,48.0,105.0,56.0,59.0,0.0,0.0,41.0,24.0]|\n",
      "|[34.0,25.0,11.0,119.0,41.0,59.0,0.0,0.0,40.0,0.0] |\n",
      "|[33.0,45.0,35.0,117.0,52.0,12.0,0.0,0.0,39.0,0.0] |\n",
      "|[37.0,20.0,24.0,121.0,52.0,47.0,0.0,0.0,37.0,0.0] |\n",
      "|[37.0,46.0,47.0,122.0,25.0,11.0,0.0,0.0,36.0,0.0] |\n",
      "|[41.0,27.0,0.0,82.0,42.0,35.0,0.0,0.0,38.0,6.0]   |\n",
      "|[32.0,42.0,35.0,117.0,9.0,0.0,0.0,0.0,35.0,0.0]   |\n",
      "|[34.0,6.0,36.0,117.0,18.0,35.0,0.0,0.0,34.0,0.0]  |\n",
      "|[29.0,25.0,12.0,98.0,30.0,0.0,0.0,0.0,33.0,1.0]   |\n",
      "|[31.0,27.0,35.0,100.0,26.0,24.0,0.0,0.0,32.0,1.0] |\n",
      "|[40.0,45.0,35.0,111.0,52.0,47.0,0.0,0.0,31.0,26.0]|\n",
      "|[38.0,22.0,11.0,75.0,35.0,59.0,0.0,0.0,30.0,38.0] |\n",
      "|[36.0,40.0,11.0,121.0,39.0,0.0,0.0,0.0,29.0,0.0]  |\n",
      "|[38.0,50.0,24.0,97.0,36.0,36.0,0.0,0.0,28.0,15.0] |\n",
      "|[38.0,31.0,47.0,106.0,0.0,0.0,0.0,0.0,27.0,13.0]  |\n",
      "|[44.0,56.0,23.0,123.0,1.0,47.0,0.0,0.0,26.0,44.0] |\n",
      "|[44.0,57.0,0.0,93.0,5.0,59.0,0.0,0.0,25.0,16.0]   |\n",
      "|[38.0,37.0,11.0,90.0,11.0,24.0,0.0,0.0,24.0,10.0] |\n",
      "|[39.0,46.0,12.0,94.0,50.0,23.0,0.0,0.0,3.0,10.0]  |\n",
      "|[42.0,5.0,59.0,86.0,28.0,48.0,0.0,0.0,3.0,9.0]    |\n",
      "|[44.0,25.0,11.0,72.0,1.0,11.0,0.0,0.0,23.0,27.0]  |\n",
      "|[45.0,34.0,11.0,94.0,10.0,11.0,0.0,0.0,22.0,16.0] |\n",
      "|[29.0,53.0,23.0,81.0,19.0,11.0,0.0,0.0,21.0,4.0]  |\n",
      "|[43.0,25.0,48.0,83.0,56.0,24.0,0.0,0.0,20.0,9.0]  |\n",
      "|[38.0,35.0,24.0,121.0,29.0,23.0,0.0,0.0,19.0,0.0] |\n",
      "|[43.0,36.0,36.0,72.0,58.0,12.0,0.0,0.0,18.0,27.0] |\n",
      "|[33.0,24.0,0.0,104.0,31.0,47.0,0.0,0.0,17.0,24.0] |\n",
      "|[35.0,56.0,23.0,77.0,48.0,0.0,0.0,0.0,16.0,17.0]  |\n",
      "|[41.0,35.0,24.0,109.0,13.0,48.0,0.0,0.0,14.0,29.0]|\n",
      "|[42.0,16.0,12.0,89.0,5.0,59.0,0.0,0.0,15.0,14.0]  |\n",
      "|[43.0,9.0,35.0,77.0,36.0,36.0,0.0,0.0,2.0,5.0]    |\n",
      "|[44.0,1.0,12.0,92.0,27.0,35.0,0.0,0.0,2.0,16.0]   |\n",
      "|[37.0,16.0,12.0,79.0,56.0,24.0,0.0,0.0,13.0,11.0] |\n",
      "|[37.0,32.0,24.0,77.0,26.0,59.0,0.0,0.0,1.0,11.0]  |\n",
      "|[39.0,49.0,48.0,84.0,53.0,23.0,0.0,0.0,1.0,8.0]   |\n",
      "|[38.0,46.0,12.0,112.0,5.0,23.0,0.0,0.0,12.0,26.0] |\n",
      "|[45.0,38.0,23.0,89.0,25.0,11.0,0.0,0.0,11.0,12.0] |\n",
      "|[39.0,31.0,12.0,119.0,48.0,35.0,0.0,0.0,10.0,41.0]|\n",
      "|[50.0,25.0,11.0,104.0,39.0,0.0,0.0,0.0,9.0,45.0]  |\n",
      "|[40.0,10.0,48.0,122.0,14.0,23.0,0.0,0.0,8.0,0.0]  |\n",
      "|[40.0,19.0,48.0,75.0,55.0,48.0,0.0,0.0,7.0,2.0]   |\n",
      "|[41.0,9.0,35.0,81.0,14.0,23.0,0.0,0.0,6.0,42.0]   |\n",
      "+--------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over all homogeneity score:  0.724587374106495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n",
      "100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user requested K = 11 , but we can only got  10 clusters.\n"
     ]
    }
   ],
   "source": [
    "result = getDecompositionbyColumn(df, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
